from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.models import Model, load_model, save_model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Dropout
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.layers.merge import concatenate
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score

df = pd.read_csv('/content/drive/MyDrive/dataset/subject_1.csv') 
df_d = df.to_numpy()
df.head()

# reshape data
def create_dataset(df_d, look_back=1):
	dataX, dataY = [], []
	for i in range(len(df_d)-look_back):
		a = df_d[i:(i+look_back), 0:12]
		dataX.append(a)
		dataY.append(df_d[i + look_back, 12])
	return np.array(dataX), np.array(dataY)
  
  # split into train and test sets
train_size = int(len(df_d) * 0.8)
test_size = len(df_d) - train_size
train, test = df_d[0:train_size,:], df_d[train_size:len(df_d),:]

look_back=18 #  timesteps
trainX, trainy = create_dataset(train, look_back)
testX, testy = create_dataset(test, look_back)

trainX.shape, trainy.shape, testX.shape, testy.shape

num_classes = len(np.unique(trainy))
trainy = tf.keras.utils.to_categorical(trainy)
testy = tf.keras.utils.to_categorical(testy)

def make_model(input_shape):
    input_layer = keras.layers.Input(input_shape)
    conv1 = keras.layers.Conv1D(filters=128, kernel_size=3, padding="valid", activation='relu')(input_layer)
    drop1 = keras.layers.Dropout(0.5)(conv1)
    pool1 = keras.layers.MaxPooling1D(pool_size=2)(conv1)
    flat1 = keras.layers.Flatten()(pool1)

    conv2 = keras.layers.Conv1D(filters=64, kernel_size=5, padding="valid", activation='relu')(input_layer)
    drop2 = keras.layers.Dropout(0.5)(conv2)
    pool2 = keras.layers.MaxPooling1D(pool_size=2)(conv2)
    flat2 = keras.layers.Flatten()(pool2)

    conv3 = keras.layers.Conv1D(filters=32, kernel_size=11, padding= "valid", activation='relu' )(input_layer)
    drop3 = keras.layers.Dropout(0.5)(conv3)
    pool3 = keras.layers.MaxPooling1D(pool_size=2)(conv3)
    flat3 = keras.layers.Flatten()(pool3)

    merged = keras.layers.concatenate([flat1, flat2, flat3])
    # interpretation
    dense1 = keras.layers.Dense(100, activation='relu')(merged)
    outputs = keras.layers.Dense(num_classes, activation='softmax')(dense1)

model = make_model(input_shape=trainX.shape[1:])

epochs = 500 
batch_size = 150

callbacks = [
    keras.callbacks.ModelCheckpoint(
        "best_model.h5", save_best_only=True, verbose=1, monitor="val_loss"
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=50, min_lr=0.001
    ),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=80, verbose=1, baseline=0.4),
]
model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy", tf.keras.metrics.Precision(name = 'precision'), tf.keras.metrics.Recall(name = 'recall')
    ],
)
history = model.fit(
    trainX,
    trainy,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2, 
    verbose=1,
)

model = tf.keras.models.load_model("best_model.h5")


rounded_labels=np.argmax(testy, axis=1)
rounded_labels[1]

y_pred = np.argmax(model.predict(testX),axis=1)
accuracy = accuracy_score(rounded_labels, y_pred)
precision = precision_score(rounded_labels, y_pred, zero_division=1)
recall = recall_score(rounded_labels, y_pred, zero_division=1)
print('Accuracy: ', accuracy*100)
print('Precision: ', precision*100)
print('Recall: ', recall*100)


